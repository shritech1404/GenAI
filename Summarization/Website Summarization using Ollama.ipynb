{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d595e7cd-7c0a-42ea-9ec7-1569e2a79ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv \n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import openai\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28a6598b-8ee7-4602-a46d-1d9a0ccfc206",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c77fc6-e530-46ba-aa08-aa3dbd09e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"what is 2+2?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad4b80b5-1cfb-42aa-8ea2-ac80054c085e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 = 4\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87497178-8d70-4d1a-9354-664f3d6db9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47301b59-e20b-4638-9380-2e3829af8b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d903734-c57f-49b9-b7d9-18ca9552674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47d79c1e-b597-4d74-a3e5-0c73599177b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70e5ef91-cd95-4ed1-8a85-342043ba12f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = ollama.chat(\n",
    "        model=MODEL, \n",
    "        messages=messages_for(website))\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7734be40-b74d-4af0-96ab-a6a8691cd224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Summary of the Website**\\n==========================\\n\\n*   The website is run by Edward Donner, a co-founder and CTO of Nebula.io, an AI company applying AI to help people discover their potential.\\n*   The main focus of the website appears to be showcasing the capabilities of Nebula.io's proprietary LLMs (Large Language Models) in talent sourcing and management.\\n*   There are resources available for learning about mastering AI and LLM engineering, transitioning from a software engineer to an AI data scientist, and using LLMs in various ways.\\n\\n**News and Announcements**\\n-------------------------\\n\\n*   **Mastering AI and LLM Engineering - Resources**: Published on November 13, 2024.\\n*   **From Software Engineer to AI Data Scientist – resources**: Published on October 16, 2024.\\n*   **Outsmart LLM Arena – a battle of diplomacy and deviousness**: Published on June 26, 2024.\\n*   **Choosing the Right LLM: Toolkit and Resources**: Published in August 2024 (exact date not specified).\\n*   A newsletter subscription is available to stay updated about new resources and information.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9231bb4-d2cc-4837-9b30-23a1071f44a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0c2d6d3-60b0-4dc6-8552-94538349c914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary**\n",
       "================\n",
       "\n",
       "* The website is run by Ed, a co-founder and CTO of Nebula.io, an AI startup that applies AI to help people discover their potential.\n",
       "* Nebla.io uses proprietary LLMs for talent matching and has patented its matching model.\n",
       "* The website features:\n",
       "\t+ An \"Outsmart\" arena where LLMs compete in diplomacy and deception challenges.\n",
       "\t+ Resources and articles on mastering AI, LLM engineering, software engineer to data scientist career paths, and choosing the right LLM.\n",
       "\n",
       "**News/Announcements**\n",
       "======================\n",
       "\n",
       "* **Mastering AI and LLM Engineering – Resources**: Published November 13, 2024\n",
       "* **From Software Engineer to AI Data Scientist – resources**: Published October 16, 2024\n",
       "* **Outsmart LLM Arena – a battle of diplomacy and deviousness**: Published June 26, 2024"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d84c723-d3ff-4474-86b7-c6e89364fb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Did you know that:\n",
       "\n",
       "* This article has over 122 million characters in its edit history!\n",
       "* There are over 1,000 languages available on Wikipedia, including many minority languages.\n",
       "* The website's URL has changed over 100 times since its inception in 2001.\n",
       "\n",
       "Let me know if you have any other questions about Wikipedia!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b4af0-c992-483e-80d1-d96ca208a50f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
